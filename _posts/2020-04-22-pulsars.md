---
title: "Classifying Pulsar Stars using Machine Learning Models"
date: 2020-04-22
tags: [data science, machine learning, scikit-learn]
header:
  image: "/images/perceptron/percept.jpg"
excerpt: "Data Science, Machine Learning, Scikit-learn"
mathjax: "true"
---

# Predicting Pulsar Stars

## Introduction

HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey. 

Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. 

As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars 
rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes. 

Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation. Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. 

Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation. 

The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. 

Attribute Information:

Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below: 

1. Mean of the integrated profile. 
2. Standard deviation of the integrated profile. 
3. Excess kurtosis of the integrated profile. 
4. Skewness of the integrated profile. 
5. Mean of the DM-SNR curve. 
6. Standard deviation of the DM-SNR curve. 
7. Excess kurtosis of the DM-SNR curve. 
8. Skewness of the DM-SNR curve. 
9. Class 

HTRU 2 Summary 
17,898 total examples. 
1,639 positive examples. 
16,259 negative examples.

## EDA


```python
import pandas as pd

pulsars = pd.read_csv("/Users/cain/Documents/Projects/Data Sets/pulsar_stars.csv")
```


```python
pulsars.info()
```


```python
pulsars.head()
```


```python
pulsars.describe()
```

## Pre-Processing


```python
from sklearn.model_selection import train_test_split

predictors = pulsars.drop('target_class', axis = 1)
target = pulsars['target_class']
X_train, X_test, y_train, y_test = train_test_split(predictors, target, 
                                                    test_size = 0.25, 
                                                    random_state = 13)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

models = []
acc = []
f1 = []
```

## Machine Learning Models

### Logistic Regression


```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
import numpy as np

classifier = LogisticRegression()

# Create regularization penalty space
penalty = ['l1', 'l2']

# Create regularization hyperparameter space
C = np.logspace(0, 4, 10)

solver = ['liblinear']

# Create hyperparameter options
hyperparameters = dict(C=C, penalty=penalty, solver=solver)

# Create grid search using 5-fold cross validation
clf = GridSearchCV(classifier, hyperparameters, cv=5, verbose = 1)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])
print('Best C:', best_model.best_estimator_.get_params()['C'])
```


```python
classifier = LogisticRegression(penalty = 'l1', C = 7.74, solver = 'liblinear')

classifier.fit(X_train, y_train)
```


```python
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

y_pred = classifier.predict(X_test)

LR_acc = accuracy_score(y_test, y_pred)
LR_f1 = f1_score(y_test, y_pred)

models.append('LR')
acc.append(LR_acc)
f1.append(LR_f1)

LR_cm = confusion_matrix(y_test, y_pred, labels = [1,0])

print('Accuracy: ', LR_acc)
print('F1 Score: ', LR_f1)
```

### kNN


```python
from sklearn.neighbors import KNeighborsClassifier

classifier = KNeighborsClassifier()

hyperparameters = {
    'n_neighbors': [3,5,7,9],
    'metric':['euclidean', 'manhattan']
}

clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best K:', best_model.best_estimator_.get_params()['n_neighbors'])
print('Best metric:', best_model.best_estimator_.get_params()['metric'])
```


```python
classifier = KNeighborsClassifier(n_neighbors = 9, metric = 'manhattan')

classifier.fit(X_train, y_train)
```


```python
y_pred = classifier.predict(X_test)

KNN_acc = accuracy_score(y_test, y_pred)
KNN_f1 = f1_score(y_test, y_pred)

models.append('KNN')
acc.append(KNN_acc)
f1.append(KNN_f1)

KNN_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', KNN_acc)
print('F1 Score: ', KNN_f1)
```

### Linear Disciminant Analysis


```python
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

classifier = LinearDiscriminantAnalysis()

classifier.fit(X_train, y_train)
```


```python
y_pred = classifier.predict(X_test)

LDA_acc = accuracy_score(y_test, y_pred)
LDA_f1 = f1_score(y_test, y_pred)

models.append('LDA')
acc.append(LDA_acc)
f1.append(LDA_f1)

LDA_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', LDA_acc)
print('F1 Score: ', LDA_f1)
```

### SVM


```python
from sklearn.svm import SVC

classifier = SVC()

hyperparameters = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best C:', best_model.best_estimator_.get_params()['C'])
```


```python
classifier = SVC(C=1000)
classifier.fit(X_train, y_train)
```


```python
y_pred = classifier.predict(X_test)

SVM_acc = accuracy_score(y_test, y_pred)
SVM_f1 = f1_score(y_test, y_pred)

models.append('SVM')
acc.append(SVM_acc)
f1.append(SVM_f1)

SVM_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', SVM_acc)
print('F1 Score: ', SVM_f1)
```

### Decision Tree


```python
from sklearn.tree import DecisionTreeClassifier

classifier = DecisionTreeClassifier(random_state = 0)

balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]
hyperparameters = dict(class_weight=balance)


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])
```


```python
classifier = DecisionTreeClassifier(class_weight = 'balanced', random_state = 0)

classifier.fit(X_train, y_train)
```


```python
from sklearn.metrics import accuracy_score
```


```python
y_pred = classifier.predict(X_test)

DT_acc = accuracy_score(y_test, y_pred)
DT_f1 = f1_score(y_test, y_pred)

models.append('DT')
acc.append(DT_acc)
f1.append(DT_f1)

DT_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', DT_acc)
print('F1 Score: ', DT_f1)
```

### Random Forest


```python
from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier(random_state = 0)

balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]
hyperparameters = dict(class_weight=balance)


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])
```


```python
classifier = RandomForestClassifier(random_state = 0, class_weight = 'balanced')

classifier.fit(X_train, y_train)
```


```python
y_pred = classifier.predict(X_test)

RF_acc = accuracy_score(y_test, y_pred)
RF_f1 = f1_score(y_test, y_pred)

models.append('RF')
acc.append(RF_acc)
f1.append(RF_f1)

RF_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', RF_acc)
print('F1 Score: ', RF_f1)
```

## Comparison of Models


```python
import numpy as np

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True, 
                          file_name='image'):
                          
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / np.sum(cm).astype('float')
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(5, 3))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True Label')
    plt.savefig(file_name)
    plt.close()
```


```python
labels = ['Pulsar', 'Noise']

plot_confusion_matrix(LR_cm,
                      target_names = labels,
                      title = 'Logistic Regression',
                      cmap = None,
                      normalize = False,
                      file_name = 'LR_cm.png')
                      
plot_confusion_matrix(KNN_cm,
                      target_names = labels,
                      title = 'KNN',
                      cmap = None,
                      normalize = False,
                      file_name = 'KNN_cm.png')                        
                      
plot_confusion_matrix(LDA_cm,
                      target_names = labels,
                      title = 'LDA',
                      cmap = None,
                      normalize = False,
                      file_name = 'LDA_cm.png')

plot_confusion_matrix(SVM_cm,
                      target_names = labels,
                      title = 'SVM',
                      cmap = None,
                      normalize = False,
                      file_name = 'SVM_cm.png')    
                      
plot_confusion_matrix(DT_cm,
                      target_names = labels,
                      title = 'Decision Tree',
                      cmap = None,
                      normalize = False,
                      file_name = 'DT_cm.png') 
                      
plot_confusion_matrix(RF_cm,
                      target_names = labels,
                      title = 'Random Forest',
                      cmap = None,
                      normalize = False,
                      file_name = 'RF_cm.png')  
```

