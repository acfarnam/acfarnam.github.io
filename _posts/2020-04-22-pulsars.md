---
title: "Classifying Pulsar Stars using Machine Learning Models"
date: 2020-04-22
tags: [data science, machine learning, scikit-learn]
header:
  image: "/images/sky.jpg"
excerpt: "Data Science, Machine Learning, Scikit-learn"
mathjax: "true"
---

# Predicting Pulsar Stars

## Introduction

HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey. 

Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. 

As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars 
rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes. 

Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation. Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. 

Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation. 

The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. 

Attribute Information:

Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below: 

1. Mean of the integrated profile. 
2. Standard deviation of the integrated profile. 
3. Excess kurtosis of the integrated profile. 
4. Skewness of the integrated profile. 
5. Mean of the DM-SNR curve. 
6. Standard deviation of the DM-SNR curve. 
7. Excess kurtosis of the DM-SNR curve. 
8. Skewness of the DM-SNR curve. 
9. Class 

HTRU 2 Summary 
17,898 total examples. 
1,639 positive examples. 
16,259 negative examples.

## EDA


```python
import pandas as pd

pulsars = pd.read_csv("/Users/cain/Documents/Projects/Data Sets/pulsar_stars.csv")
```


```python
pulsars.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 17898 entries, 0 to 17897
    Data columns (total 9 columns):
     Mean of the integrated profile                  17898 non-null float64
     Standard deviation of the integrated profile    17898 non-null float64
     Excess kurtosis of the integrated profile       17898 non-null float64
     Skewness of the integrated profile              17898 non-null float64
     Mean of the DM-SNR curve                        17898 non-null float64
     Standard deviation of the DM-SNR curve          17898 non-null float64
     Excess kurtosis of the DM-SNR curve             17898 non-null float64
     Skewness of the DM-SNR curve                    17898 non-null float64
    target_class                                     17898 non-null int64
    dtypes: float64(8), int64(1)
    memory usage: 1.2 MB



```python
pulsars.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mean of the integrated profile</th>
      <th>Standard deviation of the integrated profile</th>
      <th>Excess kurtosis of the integrated profile</th>
      <th>Skewness of the integrated profile</th>
      <th>Mean of the DM-SNR curve</th>
      <th>Standard deviation of the DM-SNR curve</th>
      <th>Excess kurtosis of the DM-SNR curve</th>
      <th>Skewness of the DM-SNR curve</th>
      <th>target_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>140.562500</td>
      <td>55.683782</td>
      <td>-0.234571</td>
      <td>-0.699648</td>
      <td>3.199833</td>
      <td>19.110426</td>
      <td>7.975532</td>
      <td>74.242225</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>102.507812</td>
      <td>58.882430</td>
      <td>0.465318</td>
      <td>-0.515088</td>
      <td>1.677258</td>
      <td>14.860146</td>
      <td>10.576487</td>
      <td>127.393580</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103.015625</td>
      <td>39.341649</td>
      <td>0.323328</td>
      <td>1.051164</td>
      <td>3.121237</td>
      <td>21.744669</td>
      <td>7.735822</td>
      <td>63.171909</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>136.750000</td>
      <td>57.178449</td>
      <td>-0.068415</td>
      <td>-0.636238</td>
      <td>3.642977</td>
      <td>20.959280</td>
      <td>6.896499</td>
      <td>53.593661</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>88.726562</td>
      <td>40.672225</td>
      <td>0.600866</td>
      <td>1.123492</td>
      <td>1.178930</td>
      <td>11.468720</td>
      <td>14.269573</td>
      <td>252.567306</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
pulsars.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mean of the integrated profile</th>
      <th>Standard deviation of the integrated profile</th>
      <th>Excess kurtosis of the integrated profile</th>
      <th>Skewness of the integrated profile</th>
      <th>Mean of the DM-SNR curve</th>
      <th>Standard deviation of the DM-SNR curve</th>
      <th>Excess kurtosis of the DM-SNR curve</th>
      <th>Skewness of the DM-SNR curve</th>
      <th>target_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
      <td>17898.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>111.079968</td>
      <td>46.549532</td>
      <td>0.477857</td>
      <td>1.770279</td>
      <td>12.614400</td>
      <td>26.326515</td>
      <td>8.303556</td>
      <td>104.857709</td>
      <td>0.091574</td>
    </tr>
    <tr>
      <th>std</th>
      <td>25.652935</td>
      <td>6.843189</td>
      <td>1.064040</td>
      <td>6.167913</td>
      <td>29.472897</td>
      <td>19.470572</td>
      <td>4.506092</td>
      <td>106.514540</td>
      <td>0.288432</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5.812500</td>
      <td>24.772042</td>
      <td>-1.876011</td>
      <td>-1.791886</td>
      <td>0.213211</td>
      <td>7.370432</td>
      <td>-3.139270</td>
      <td>-1.976976</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>100.929688</td>
      <td>42.376018</td>
      <td>0.027098</td>
      <td>-0.188572</td>
      <td>1.923077</td>
      <td>14.437332</td>
      <td>5.781506</td>
      <td>34.960504</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>115.078125</td>
      <td>46.947479</td>
      <td>0.223240</td>
      <td>0.198710</td>
      <td>2.801839</td>
      <td>18.461316</td>
      <td>8.433515</td>
      <td>83.064556</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>127.085938</td>
      <td>51.023202</td>
      <td>0.473325</td>
      <td>0.927783</td>
      <td>5.464256</td>
      <td>28.428104</td>
      <td>10.702959</td>
      <td>139.309331</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>192.617188</td>
      <td>98.778911</td>
      <td>8.069522</td>
      <td>68.101622</td>
      <td>223.392140</td>
      <td>110.642211</td>
      <td>34.539844</td>
      <td>1191.000837</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



## Pre-Processing


```python
from sklearn.model_selection import train_test_split

predictors = pulsars.drop('target_class', axis = 1)
target = pulsars['target_class']
X_train, X_test, y_train, y_test = train_test_split(predictors, target, 
                                                    test_size = 0.25, 
                                                    random_state = 13)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

models = []
acc = []
f1 = []
```

## Machine Learning Models

### Logistic Regression


```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
import numpy as np

classifier = LogisticRegression()

# Create regularization penalty space
penalty = ['l1', 'l2']

# Create regularization hyperparameter space
C = np.logspace(0, 4, 10)

solver = ['liblinear']

# Create hyperparameter options
hyperparameters = dict(C=C, penalty=penalty, solver=solver)

# Create grid search using 5-fold cross validation
clf = GridSearchCV(classifier, hyperparameters, cv=5, verbose = 1)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])
print('Best C:', best_model.best_estimator_.get_params()['C'])
```

    Fitting 5 folds for each of 20 candidates, totalling 100 fits


    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.


    Best Penalty: l1
    Best C: 7.742636826811269


    [Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished



```python
classifier = LogisticRegression(penalty = 'l1', C = 7.74, solver = 'liblinear')

classifier.fit(X_train, y_train)
```




    LogisticRegression(C=7.74, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=100,
                       multi_class='warn', n_jobs=None, penalty='l1',
                       random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                       warm_start=False)




```python
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

y_pred = classifier.predict(X_test)

LR_acc = accuracy_score(y_test, y_pred)
LR_f1 = f1_score(y_test, y_pred)

models.append('LR')
acc.append(LR_acc)
f1.append(LR_f1)

LR_cm = confusion_matrix(y_test, y_pred, labels = [1,0])

print('Accuracy: ', LR_acc)
print('F1 Score: ', LR_f1)
```

    Accuracy:  0.9812290502793296
    F1 Score:  0.8891820580474934


### kNN


```python
from sklearn.neighbors import KNeighborsClassifier

classifier = KNeighborsClassifier()

hyperparameters = {
    'n_neighbors': [3,5,7,9],
    'metric':['euclidean', 'manhattan']
}

clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best K:', best_model.best_estimator_.get_params()['n_neighbors'])
print('Best metric:', best_model.best_estimator_.get_params()['metric'])
```

    Fitting 3 folds for each of 8 candidates, totalling 24 fits


    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.


    Best K: 9
    Best metric: euclidean


    [Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    3.6s finished



```python
classifier = KNeighborsClassifier(n_neighbors = 9, metric = 'manhattan')

classifier.fit(X_train, y_train)
```




    KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                         metric_params=None, n_jobs=None, n_neighbors=9, p=2,
                         weights='uniform')




```python
y_pred = classifier.predict(X_test)

KNN_acc = accuracy_score(y_test, y_pred)
KNN_f1 = f1_score(y_test, y_pred)

models.append('KNN')
acc.append(KNN_acc)
f1.append(KNN_f1)

KNN_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', KNN_acc)
print('F1 Score: ', KNN_f1)
```

    Accuracy:  0.9818994413407821
    F1 Score:  0.8935611038107751


### Linear Disciminant Analysis


```python
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

classifier = LinearDiscriminantAnalysis()

classifier.fit(X_train, y_train)
```




    LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
                               solver='svd', store_covariance=False, tol=0.0001)




```python
y_pred = classifier.predict(X_test)

LDA_acc = accuracy_score(y_test, y_pred)
LDA_f1 = f1_score(y_test, y_pred)

models.append('LDA')
acc.append(LDA_acc)
f1.append(LDA_f1)

LDA_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', LDA_acc)
print('F1 Score: ', LDA_f1)
```

    Accuracy:  0.9776536312849162
    F1 Score:  0.8626373626373626


### SVM


```python
from sklearn.svm import SVC

classifier = SVC()

hyperparameters = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best C:', best_model.best_estimator_.get_params()['C'])
```

    Fitting 3 folds for each of 4 candidates, totalling 12 fits


    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   43.3s finished


    Best C: 1000



```python
classifier = SVC(C=1000)
classifier.fit(X_train, y_train)
```




    SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,
        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
        kernel='rbf', max_iter=-1, probability=False, random_state=None,
        shrinking=True, tol=0.001, verbose=False)




```python
y_pred = classifier.predict(X_test)

SVM_acc = accuracy_score(y_test, y_pred)
SVM_f1 = f1_score(y_test, y_pred)

models.append('SVM')
acc.append(SVM_acc)
f1.append(SVM_f1)

SVM_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', SVM_acc)
print('F1 Score: ', SVM_f1)
```

    Accuracy:  0.9803351955307262
    F1 Score:  0.8845144356955381


### Decision Tree


```python
from sklearn.tree import DecisionTreeClassifier

classifier = DecisionTreeClassifier(random_state = 0)

balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]
hyperparameters = dict(class_weight=balance)


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])
```

    Fitting 3 folds for each of 5 candidates, totalling 15 fits


    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.


    Best weight: {0: 1, 1: 1}


    [Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.1s finished



```python
classifier = DecisionTreeClassifier(class_weight = 'balanced', random_state = 0)

classifier.fit(X_train, y_train)
```




    DecisionTreeClassifier(class_weight='balanced', criterion='gini',
                           max_depth=None, max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, presort=False,
                           random_state=0, splitter='best')




```python
from sklearn.metrics import accuracy_score
```


```python
y_pred = classifier.predict(X_test)

DT_acc = accuracy_score(y_test, y_pred)
DT_f1 = f1_score(y_test, y_pred)

models.append('DT')
acc.append(DT_acc)
f1.append(DT_f1)

DT_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', DT_acc)
print('F1 Score: ', DT_f1)
```

    Accuracy:  0.9678212290502793
    F1 Score:  0.8208955223880595


### Random Forest


```python
from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier(random_state = 0)

balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]
hyperparameters = dict(class_weight=balance)


clf = GridSearchCV(classifier, hyperparameters, 
                   verbose = 1, cv = 3)

# Fit grid search
best_model = clf.fit(X_train, y_train)

# View best hyperparameters
print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])
```

    Fitting 3 folds for each of 5 candidates, totalling 15 fits


    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)
    [Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.0s finished
    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)


    Best weight: {0: 100, 1: 1}



```python
classifier = RandomForestClassifier(random_state = 0, class_weight = 'balanced')

classifier.fit(X_train, y_train)
```

    /Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
      "10 in version 0.20 to 100 in 0.22.", FutureWarning)





    RandomForestClassifier(bootstrap=True, class_weight='balanced',
                           criterion='gini', max_depth=None, max_features='auto',
                           max_leaf_nodes=None, min_impurity_decrease=0.0,
                           min_impurity_split=None, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=10, n_jobs=None, oob_score=False,
                           random_state=0, verbose=0, warm_start=False)




```python
y_pred = classifier.predict(X_test)

RF_acc = accuracy_score(y_test, y_pred)
RF_f1 = f1_score(y_test, y_pred)

models.append('RF')
acc.append(RF_acc)
f1.append(RF_f1)

RF_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

print('Accuracy: ', RF_acc)
print('F1 Score: ', RF_f1)
```

    Accuracy:  0.9812290502793296
    F1 Score:  0.8891820580474934


## Comparison of Models


```python
import numpy as np

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True, 
                          file_name='image'):
                          
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / np.sum(cm).astype('float')
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(5, 3))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True Label')
    plt.savefig(file_name)
    plt.close()
```


```python
labels = ['Pulsar', 'Noise']

plot_confusion_matrix(LR_cm,
                      target_names = labels,
                      title = 'Logistic Regression',
                      cmap = None,
                      normalize = False,
                      file_name = 'LR_cm.png')
                      
plot_confusion_matrix(KNN_cm,
                      target_names = labels,
                      title = 'KNN',
                      cmap = None,
                      normalize = False,
                      file_name = 'KNN_cm.png')                        
                      
plot_confusion_matrix(LDA_cm,
                      target_names = labels,
                      title = 'LDA',
                      cmap = None,
                      normalize = False,
                      file_name = 'LDA_cm.png')

plot_confusion_matrix(SVM_cm,
                      target_names = labels,
                      title = 'SVM',
                      cmap = None,
                      normalize = False,
                      file_name = 'SVM_cm.png')    
                      
plot_confusion_matrix(DT_cm,
                      target_names = labels,
                      title = 'Decision Tree',
                      cmap = None,
                      normalize = False,
                      file_name = 'DT_cm.png') 
                      
plot_confusion_matrix(RF_cm,
                      target_names = labels,
                      title = 'Random Forest',
                      cmap = None,
                      normalize = False,
                      file_name = 'RF_cm.png')  
```


